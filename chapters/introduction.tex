\chapter{Introduction}
\label{cha:introduction}

For a machine to interact in an intelligent manner with its outside world it needs to be
equipped with suitable knowledge.  The very same is true for humans, and acquiring this
knowledge is a highly complex task which up to today is not completely understood.  To
help within this process, previously acquired knowledge is \emph{represented} in different
ways, \eg as books or films, to help others learning it.

However, the way knowledge is represented for human consumption is almost always not
suitable for machines.  While humans can extract knowledge from natural language, which
may be full of ambiguity, machines require precise formulations of knowledge.  The
representation of knowledge in a machine-understandable way is the main focus of the area
of \emph{knowledge representation}~\cite{KRhandbook}.

One of the most successful approaches to knowledge representations are description
logics~\cite{DLhandbook}, a family of logic-based knowledge representations formalisms
with varying expressivity and reasoning complexity.  Description logics allow to represent
knowledge as \emph{knowledge bases}, or \emph{ontologies}.  Essentially, these are
collections of axioms, which may be either \emph{assertional} or \emph{terminological}.
For example, to represent the fact (the \emph{assertion}) that an individual \textsf{tom}
is a cat, one can use the assertional axiom
\begin{equation}
  \label{eq:14}
  \mathsf{Cat}(\mathsf{tom}).
\end{equation}
On the other hand, to state the terminological knowledge that every cat hunts mice, one
can use so-called \emph{general concept inclusions} (GCIs) and write
\begin{equation}
  \label{eq:15}
  \mathsf{Cat} \sqsubseteq \exists \mathsf{hunts}. \mathsf{Mouse}.
\end{equation}
As soon as a knowledge base is available, it is possible to \emph{reason} with it, \ie to
extract knowledge from it that is implicitly contained.  For example, from the two axioms
stated above, we can infer that the individual \textsf{tom} hunts mice, although this has
never been stated explicitly.

Knowledge bases can be used to represent knowledge in a machine-consumable way.  However,
the question arises how such knowledge bases can be obtain.  In one way or the other,
knowledge which is available to humans has to be translated into the form of a description
logic knowledge base.  Of course, this could be done by humans, but this approach would
not only be very time-consuming, but also prone to errors.  An automatic translations
would thus be highly welcome.  On the other hand, a completely automatic translation would
just mean that machines can consume knowledge in the way humans represent it, an
assumption which is not reasonable.

However, one can still think about approaches which are \emph{semi-automatic} in the sense
that the results obtained from such a translation are preliminary, requiring further
refinement, or that the translation procedure requires additional \emph{assistance} by
means of human experts.

An approach to achieve such a semi-automatic translation procedure, or \emph{learning
  procedure}, has been made in~\cite{Diss-Felix}.  There, the focus lied in extracting
terminological knowledge of the form as given in \Cref{eq:14} from some given \emph{finite
  interpretation} $\mathcal{I}$.  More precisely, the procedures described
in~\cite{Diss-Felix} would automatically learn all GCIs which are \emph{valid} in the data
set $\mathcal{I}$.  This approach made use of the mathematical theory of \emph{formal
  concept analysis}, a subfield of mathematical order theory which has very close
connections to description logics.

Of course, the GCIs learned this way may not be correct, in the sense that the GCI may
hold in $\mathcal{I}$, but this data missed to contain some relevant counterexamples.  One
way to remedy this is to use an algorithm from formal concept analysis called
\emph{attribute exploration}.  Within this algorithm, an expert (possibly human) is asked
extracted GCIs for there correctness, and if such a GCI is not correct, the expert has to
provide \emph{counterexamples} for it.  This way, the problem that the data may be
\emph{incomplete}, in the sense it lacks crucial counterexamples, can be solved.  This has
also been done in~\cite{Diss-Felix}.

However, there are still problems with the original approach of~\cite{Diss-Felix}, in
particular if it comes to the \emph{quality} of the data $\mathcal{I}$ from which GCIs are
learned.  The main problem here is that the data may contain \emph{errors}.  These errors
may either cause otherwise valid GCIs not to be found, because these errors act as
\emph{false counterexamples}, or GCIs are found which are not correct because errors cause
positive counterexamples to vanish.  While the latter approach can in theory be handled by
the attribute exploration approach sketched above, the former cannot, because the approach
discussed in~\cite{Diss-Felix} will not even extract GCIs for which there may be false
counterexamples in $\mathcal{I}$.

In this work, we want to extent the results obtain in~\cite{Diss-Felix} to this new
setting of where the data $\mathcal{I}$ may contain errors.  The main approach for this is
to transfer the notion of \emph{confidence}~\cite{arules:agrawal:association-rules} from
the area of data-mining to GCIs.  Intuitively, this means that GCIs may have \emph{few}
errors in the data, as opposed to having none in the original approach
of~\cite{Diss-Felix}.  The notion of ``few'' is quantified by means of the confidence of
the GCIs in the data.

In the following, we shall give a more in-depth discussion of what we ant to do in this
work.  To this end, we shall first introduce description logics and formal concept
analysis, in a exemplary and historic manner.  Thereafter, we shall discuss the main
results of~\cite{Diss-Felix} in more detail, and also briefly mention some other related
work.  Finally, we present the main contributions of this work.

\section{Description Logics}
\label{sec:repr-knowl-using}

Description logics~\cite{DLhandbook} are a family of logic-based knowledge representation
formalisms, with a strong emphasis on well-defined semantics and practical reasoning
procedures.  The family of description logics contains various flavors of logical
formalisms, varying in expressiveness and reasoning complexity, allowing users to choose
the expressiveness they need, or the complexity they can afford in their respective
applications.

The development of description logics~\cite{journals/sLogica/BaaderS01} was motivated by
earlier knowledge representation formalisms like \emph{semantic
  networks}~\cite{SemanticNetworks} or \emph{frame}~\cite{Minsky-Frames}, whose semantics
were highly ambiguous, and mostly depended on human interpretation or implementation
details.  The need for well-defined and predictable knowledge representation formalisms
then lead to the first logic-based systems~\cite{journals/cogsci/BrachmanS85}, which were
however incomplete~\cite{conf/kr/Schmidt-Schauss89}.

The first description logics considered were relatively small fragments of first order
logic, but already for them it could be shown that reasoning is
intractable~\cite{conf/aaai/BrachmanL84,journals/ai/Nebel88}.  One approach to remedy this
was to investigate highly optimized reasoning algorithms, which behave well in practice.
The most prominent class of such algorithms are \emph{tableau algorithms}, first invented
for the description logic
$\ALC$~\cite{journals/ai/Schmidt-SchaussS91,conf/ecai/HollunderNS90} for the subsumption
problem, and thereafter extended to other, even more expressive logics.  After a
connection of $\ALC$ to multimodal logic $\mathsf{K}_{(\mathsf{m})}$ was
discovered~\cite{DBLP:conf/ijcai/Schild91}, it was seen that this tableau algorithm is
actually a re-invention of the tableau algorithms used in modal logics.  The development
of description logics continued to investigate highly expressive description logics, whose
expressiveness exceeds that of $\ALC$, but which still behave well in
practice~\cite{journals/igpl/HorrocksST00}, and for which highly-optimized implementations
exist~\cite{sirin_pellet:practical_2007,Haarslev:2001,DBLP:conf/cade/TsarkovH06}.  This
finally lead to the adoption of the \emph{Web Ontology Language OWL} by the W3C, which is
based on the highly expressive description logic
$\mathcal{S}\mathcal{H}\mathcal{O}\mathcal{I}\mathcal{N}$~\cite{horrocks03fromshiqrdftoowl}.

The focus of description logics research departed from the sole focus on expressive
description logics when it was discovered at the beginning of this millennium that for the
inexpressive description logic $\EL$ reasoning is
tractable~\cite{DBLP:conf/ijcai/Baader03a,DBLP:conf/ecai/Brandt04}, and stays polynomial
if the expressiveness of $\EL$ is extended
slightly~\cite{DBLP:conf/ijcai/BaaderBL05,BaaderEtAl-OWLED08DC}.  The practical relevance
of these results is given by the fact that large biomedical ontologies can be reformulated
as \emph{description logic knowledge bases} (or \emph{description logic ontologies}) using
just $\EL$ or a slight extension of it.  Examples for this are the \emph{Systematized
  Nomenclature of Medicine--Clinical Terms}, the Gene Ontology~\cite{gene-ontology}, and
large parts of the GALEN ontology~\cite{Rector199475}.

The term \enquote{description} in \enquote{description logics} is motivated by the
intention to use description logics to express knowledge about \emph{concepts
  descriptions}.  For this, description logics provide a number of constructors, which can
then be used to build concept descriptions from atomic \emph{concept names} and binary
\emph{role names}.  For example, the description logic $\EL$ provides the constructors
\emph{conjunction} ($\sqcap$) and \emph{existential restriction} ($\exists$), and examples
of $\EL$ concept descriptions are
\begin{equation*}
  \mathsf{Cat},\, \mathsf{Cat} \sqcap \mathsf{Mouse},\, \exists \mathsf{hunts}. \mathsf{Mouse},
\end{equation*}
where \textsf{Cat}, \textsf{Mouse} are concept names, and \textsf{hunts} is a role name.

A description logic knowledge base formulated in $\EL$ consist, as most description logic
knowledge bases, of two parts, namely an \emph{ABox}, holding assertional knowledge, and a
\emph{TBox}, containing terminological knowledge.  An example knowledge base is
\begin{equation*}
  \mathcal{K} = (\set{ \mathsf{Cat} \sqsubseteq \exists \mathsf{hunts}. \mathsf{Mouse} },
  \set{ \mathsf{Cat}(\mathsf{tom}) }),
\end{equation*}
where the first entry denotes the TBox, and the second one denotes the ABox.  The
semantics of knowledge bases is defined using \emph{interpretations} $\mathcal{I}$, which
can be thought of as directed edge- and vertex-labeled graphs.  The labels of the
vertices, which we shall \emph{elements} or \emph{individuals}, are concept names, and the
labels of the edges are role names.  An interpretation is a model of a knowledge base if
all elements \emph{satisfy} the axioms contained in this knowledge base.  For example, the
interpretation
\begin{center}
  \begin{tikzpicture}[>=stealth']
    \begin{scope}[every node/.style = { draw, circle }]
      \node (Tom) {\textsf{tom}};
      \node[right=2cm of Tom, inner sep = .1cm] (Jerry) {\textsf{jerry}}; % fix
    \end{scope}
    \path (Tom) edge[->, bend left=30] node[midway, above] {\textsf{hunts}} (Jerry);
    \path (Jerry) edge[->, bend left=30] node[midway, below] {\textsf{hunts}} (Tom);
  \end{tikzpicture}
\end{center}
is a model of the knowledge base $\mathcal{K}$, since the element \textsf{tom} is labeled
with \textsf{Cat}, and every element which is labeled with \textsf{Cat} is connected to
some element labeled with \textsf{Mouse} via an edge labeled with \textsf{hunts}.

As soon as one has a description logic knowledge base, one can conduct \emph{reasoning}
with it, \ie one can extract knowledge from the knowledge base which may only be contained
implicitly in it.  Two classical reasoning problems are \emph{instance checking} and
\emph{subsumption}: given an \emph{individual name} $a$ and a concept description $C$, the
instance checking problem is to ask whether $a$ is an \emph{instance} of $C$, \ie whether
$a$ satisfies the concept description $C$ in every interpretation.  The subsumption
problem is to ask, given two concept descriptions $C$ and $D$, whether it is true that $C$
is a \emph{subconcept} of $D$, \ie whether it is true in every interpretation that every
element that satisfies $C$ also satisfies $D$.  Other reasoning problems are
\emph{knowledge base consistency} and \emph{concept satisfiability}: a knowledge base is
consistent if it has a model, and a concept description $C$ is satisfiable with respect to
a given knowledge base $\mathcal{K}$ if there exists a model of $\mathcal{K}$ containing
elements that satisfy $C$.  Deciding knowledge base consistency and concept satisfiability
are mostly relevant to ensure the correctness of the given knowledge base.

\section{Formal Concept Analysis}
\label{sec:learn-impl-using}

Formal concept analysis~\cite{fca-book} is a subfield of mathematical order theory,
originally concerned with the study of properties of ordered structures called
\emph{complete lattices} by representing them in terms of so-called \emph{formal
  contexts}.  Since then, formal concept analysis has considerably broadened its scope,
with connections to previously unrelated subjects such as
logics~\cite{books/math/Prediger00,conf/iccs/FerreR00}, data
mining~\cite{arules:Zaki:1998}, machine learning~\cite{conf/icfca/Kuznetsov04}, and
artificial intelligence~\cite{phd/de/Rudolph2006,Diss-Felix}.  Because of this, formal
concept analysis can today be considered as a part of theoretical computer science, and
thus provides another link between compute science and mathematics.

The origin of formal concept analysis as it is used in this work can clearly be marked by
the work of Wille~\cite{fca:Wille:1982}, which introduced formal concept analysis as an
approach to impose meaning on complete lattices by considering them as \emph{hierarchies
  of concepts}.  This work was motivated by previous results from
Birkhoff~\cite{books/math/Birkhoff67}, but also has a strong philosophical
background~\cite{books/phil/Hentig72,Wille:Begriffsdenken}.  Another early work that
included some of the ideas of formal concept analysis is~\cite{OrdreEtClassification}.

\begin{figure}[tp]
  \centering
  \begin{math}
    \begin{array}[c]{c|*{7}{c}}
      \toprule
      ~       & \mathsf{small} & \mathsf{medium} & \mathsf{large} & \mathsf{inner} &
      \mathsf{outer} & \mathsf{moon} & \mathsf{no moon} \\
      \midrule
      \mathsf{Mercury} & \times &   &   & \times &   &   & \times  \\
      \mathsf{Venus}   & \times &   &   & \times &   &   & \times  \\
      \mathsf{Earth}   & \times &   &   & \times &   & \times &    \\
      \mathsf{Mars}    & \times &   &   & \times &   & \times &    \\
      \mathsf{Jupiter} &   &   & \times &   & \times & \times &    \\
      \mathsf{Saturn}  &   &   & \times &   & \times & \times &    \\
      \mathsf{Uranus}  &   & \times &   &   & \times & \times &    \\
      \mathsf{Neptune} &   & \times &   &   & \times & \times &    \\
      \mathsf{Pluto}   & \times &   &   &   & \times & \times &    \\
      \bottomrule
    \end{array}
  \end{math}
  \caption{Example Formal Context (taken from~\cite{fca:Wille:1982})}
  \label{fig:example-formal-context}
\end{figure}

The fundamental idea of formal concept analysis is to represent complete lattices by a
\emph{object-attribute-relationship}, which is expressed using \emph{formal contexts}.
These structures can be thought of as \emph{tables of crosses}.  An example of a formal
context is depicted in \Cref{fig:example-formal-context}.  This example formal context
expresses an object-attribute-relationship between the \emph{objects} being the known
planets of the solar system (including Pluto), and the \emph{attributes} being certain
properties of these planets, like its size (\textsf{small}, \textsf{medium}, or
\textsf{large}), its distance from the sun (\textsf{inner} planet (\ie has an orbit which
is closer to the sun than the asteroid belt), or is an \textsf{outer} planet), and it has
a \textsf{moon} or not.  A cross in this table then means that the object on the
corresponding row \emph{has} the attribute on the corresponding column.  Thus, for
example, \textsf{Mercury} is a \textsf{small} planet, and \textsf{Pluto} is an
\textsf{outer} planet.  The set of all pairs of objects $g$ and attributes $m$ where $g$
has the attribute $m$ is called the \emph{incidence relation} of the formal context.

Formally, a \emph{formal context} $\con K$ can be defined as a triple $\con K = (G, M,
I)$, where $G$ and $M$ are sets and $I \subseteq G \times M$.  The set $G$ is then called
the set of \emph{objects}, the set $M$ is called the set of \emph{attributes}, and the set
$\mathcal{I}$ is called the \emph{incidence}.  An object $g \in G$ \emph{has} an attribute
$m \in M$ in $\con K$ if and only if $(g, m) \in I$.

From such a formal context one can then extract \emph{formal concepts}, which can be
ordered in a natural way to yield the \emph{concept lattice} of the formal context.  In
our example above, a formal concept which corresponds to the concept of a
\emph{medium-sized planet in our known solar system} would be the tuple
\begin{equation}
  \label{eq:60}
  ( \set{ \mathsf{Uranus}, \mathsf{Neptune} }, \set{ \mathsf{medium}, \mathsf{moon},
    \mathsf{outer} } ),
\end{equation}
where the first set is called the \emph{extent}, and the second set is called the
\emph{intent} of the formal concept.

Formal concepts can then be ordered by set-inclusion of their extents, and it can be shown
that the thus-obtained ordered set is a complete lattice, the \emph{concept lattice} of
the formal context.  The concept lattice that corresponds to our small example above is
shown in \ref{fig:example-concept-lattice}.  This diagram also uses the usual, abridged
annotation of concept lattices: a node $v$ in the lattice diagram represents the formal
concept whose extent consists of all objects which can be reached by an \emph{descending
  path} in the diagram, starting from $v$.  Likewise, the intent of $v$ is the set of all
attributes that can be reached by an \emph{ascending path} in the diagram, starting from
$v$.  Thus, the gray-shaded node in \Cref{fig:example-concept-lattice} is the formal
concept of \Cref{eq:60}.

\begin{figure}[tp]
  \tikzset{vertexbase/.style={semithick, shape=circle, inner sep=2pt, outer sep=0pt, draw},%
    vertex/.style={vertexbase},%
    mivertex/.style={vertexbase},%
    jivertex/.style={vertexbase},%
    divertex/.style={vertexbase},%
    conn/.style={-, thick}%
  }
  \begin{center}
    \begin{tikzpicture}
      \begin{scope}[xscale=.7] %for scaling and the like
        \begin{scope} %draw vertices
          \foreach \nodename/\nodetype/\xpos/\ypos in {%
            0/vertex/2/4,
            1/divertex/-4/7,
            2/jivertex/0/7,
            3/divertex/8/7,
            5/jivertex/4/7,
            6/mivertex/-2/8,
            7/vertex/2/8,
            8/mivertex/6/8,
            9/mivertex/0/9,
            10/mivertex/4/9,
            11/vertex/2/10
          } \node[\nodetype] (\nodename) at (\xpos, \ypos) {};
          \node[divertex,fill=black!30] (4) at (6,7) {};
        \end{scope}
        \begin{scope} %draw connections
          \path (7) edge[conn] (10);
          \path (9) edge[conn] (11);
          \path (5) edge[conn] (8);
          \path (1) edge[conn] (6);
          \path (0) edge[conn] (4);
          \path (0) edge[conn] (3);
          \path (8) edge[conn] (10);
          \path (5) edge[conn] (7);
          \path (6) edge[conn] (9);
          \path (2) edge[conn] (7);
          \path (0) edge[conn] (1);
          \path (3) edge[conn] (8);
          \path (2) edge[conn] (6);
          \path (10) edge[conn] (11);
          \path (7) edge[conn] (9);
          \path (4) edge[conn] (8);
          \path (0) edge[conn] (2);
          \path (0) edge[conn] (5);
        \end{scope}
        \begin{scope}[every label/.style={font=\sffamily, inner sep=1pt, fill opacity=.9,
            text opacity=1, fill=white, label distance=4pt}] %add labels
          \foreach \nodename/\labelpos/\labelopts/\labelcontent in {%
            1/below left//{\parbox{1.4cm}{Mercury\\ Venus}},
            1/above left//{no-moon},
            2/below//{\parbox{2cm}{\centering Mars\\ Earth}},
            3/below right//{\parbox{2cm}{Jupiter\\ Saturn}},
            3/above right//{large},
            4/below//{\parbox{1.4cm}{\centering Uranus\\ Neptune}},
            5/below//{Pluto},
            6/above left//{inner},
            8/above right//{outer},
            9/above left//{small},
            10/above right//{moon}
          } \node[draw=none,label={[\labelopts]\labelpos:{\labelcontent}}] at (\nodename) {};
          \node[draw=none,label={[label distance=1pt]above:medium}] at (4) {};
        \end{scope}
      \end{scope}
    \end{tikzpicture}
  \end{center}
  \caption{Example Concept Lattice}
  \label{fig:example-concept-lattice}
\end{figure}

One of the key results of formal concepts analysis is that every complete lattice can be
represented as a concept lattice of a suitably chosen formal context (this is the
so-called \emph{fundamental theorem of formal concept analysis}).  A major direction of
formal concept analysis research is to consider properties and operations of lattices,
such as \emph{distributivity}, \emph{modularity}, \emph{direct} and \emph{semi-direct
  products}, and transfer them to corresponding properties and operations on the level of
formal contexts.  See~\cite{fca-book} for more details on this.

Another very prominent research direction in formal concept analysis is the study of
\emph{implications} in formal contexts, which has been discussed as early
as~\cite{fca:Wille:1982}.  Observe that in our example formal context above, all outer
planets have a moon.  We can express this fact as saying that the implication
\begin{equation*}
  \set{ \mathsf{outer} } \to \set{ \mathsf{moon} }
\end{equation*}
\emph{holds} in our formal context.  Implications are similar to \emph{functional
  dependencies} from the theory of databases~\cite{DBLP:books/cs/Maier83}, and also play a
certain role in classical order theory~\cite{Wild1994118}.

One task is to compute the set of all valid implications of a given formal context.  Since
this set can be quite large, one usually wants to compute \enquote{small} sets of
implications which are sufficient, called \emph{bases}.  One very prominent base is the
so-called \emph{canonical base}~\cite{fca:DuquenneGuigues:1986} (also \emph{stem base},
\emph{Duquenne-Guigues base}), which is a \emph{minimal} base, \ie a base with minimal
cardinality.  This base can be computed
effectively~\cite{DBLP:conf/icfca/Ganter10,DBLP:journals/amai/ObiedkovD07}, however these
algorithms not efficient~\cite{DBLP:conf/icfca/Distel10} with respect to size of the input
and the output.  Certain complexity results suggest that efficiently computing the
canonical base is not possible in general~\cite{DBLP:journals/dam/BabinK13}.  However, if
this is really the case is an open research question.  Therefore, other bases have been
investigated, whose computation is algorithmically easier.  An example is the base of
\emph{proper premises}~\cite{fca-book}, for which fast algorithms
exist~\cite{RyDiBo-AMAI13}.

An algorithm which is related to the study of valid implications of formal contexts is
\emph{attribute exploration}~\cite{fca-book,GORS-book}, which is an interactive process
which extracts valid implications from \emph{incomplete} data utilizing \emph{expert
  interaction} to obtain missing facts.  Within this process, an external expert is asked
questions of the form
\begin{equation*}
  \text{Is the implication } A \to B \text{ valid?}
\end{equation*}
The expert can the either accept this implication, or decline it by providing a
\emph{counterexample}.  In this way, the expert enriches the currently known formal
context by missing objects and their attributes.  As soon as the process finishes, the set
of confirmed implications represents the whole implicational knowledge represented by the
expert.  Moreover, it can be shown that the set of confirmed implications is the canonical
base of the formal context which consists of the initially known objects together with all
counterexamples provided by the expert.  In this way, attribute exploration can be seen as
an semi-automatic knowledge acquisition algorithm.

Attribute exploration has been a major focus of formal concept analysis research, and many
extensions of this algorithm have been developed and discussed.  Examples for this are the
inclusion of \emph{background
  knowledge}~\cite{stumme96attribute,DBLP:journals/tcs/Ganter99}, \emph{concept
  exploration}~\cite{conf/iccs/Stumme97}, \emph{rule
  exploration}~\cite{phd/de/Zickwolff1991}, \emph{relational
  exploration}~\cite{phd/de/Rudolph2006}, exploration in the presence of \emph{partial
  knowledge}~\cite{book/fca/BurmeisterH05,conf/ijcai/BaaderGSS07}, and \emph{model
  exploration}~\cite{Diss-Felix}.

\section{Extracting Terminological Knowledge from Relational Data}
\label{sec:extr-term-knowl}

The main purpose of this work is to discuss a way to extract general concept inclusions
from interpretations which are allowed to contain errors.  The basis for our
considerations are the results obtained by Baader and
Distel~\cite{Diss-Felix,BaDi09,BaaderDistel08} on computing \emph{finite bases} of
\emph{valid} GCIs from finite interpretations.  In the following, we shall briefly
summarize the main results o this approach.

The goal of the work by Baader and Distel is to learn terminological knowledge about a
certain \emph{domain} of interest.  For this we assume that we can represent this domain
as a finite interpretation $\mathcal{I}$, \ie our domain is representable as relational
data.  The terminological knowledge we are then interested in is the set
$\Th(\mathcal{I})$ of valid GCIs of $\mathcal{I}$, using the description logic $\ELbot$.

A first problem here is that the set $\Th(\mathcal{I})$ is infinite in general: if $C
\sqsubseteq D$ is valid in $\mathcal{I}$, and if $r$ is a role name, then the GCI $\exists
r. C \sqsubseteq \exists r. D$ is also valid in $\mathcal{I}$.  To remedy this, Baader and
Distel compute \emph{finite bases} of $\Th(\mathcal{I})$, \ie finite subsets $\mathcal{B}$
of $\Th(\mathcal{I})$ which are already \emph{complete} for $\mathcal{I}$.  In other
words, finite bases $\mathcal{B}$ are finite sets of valid GCIs of $\mathcal{I}$, such
that every GCI valid in $\mathcal{I}$ is already entailed by $\mathcal{B}$.  One of the
main results of their approach is that such finite bases always exist, and that they can
be computed effectively.

To provide these results, Baader and Distel exploit the tight connection between the
description logic $\ELbot$ and formal concept analysis, established by \emph{model based
  most specific concept descriptions} and \emph{induced formal contexts} of finite
interpretations and sets of concept descriptions.  More precisely, it can be shown that if
$\con K_{\mathcal{I}}$ denotes the induced formal context of $\mathcal{I}$, that then
every base of $\con K_{\mathcal{I}}$ gives rise to a finite base of $\mathcal{I}$.  A
technical problem that arises here is that model-based most-specific concept descriptions
are not necessarily expressible in the description logic \ELbot.  Because, of this, Baader
and Distel consider the description logic \ELgfpbot, an extension of \ELbot by
\emph{cyclic concept description} using \emph{greatest fixpoint semantics}.

The resulting algorithms for computing bases of finite interpretations all effective.  A
preliminary implementation with applications to linked data has been presented
in~\cite{DBLP:conf/icdm/BorchmannD11}.

An additional issue addressed by Baader and Distel is the fact that the interpretation
$\mathcal{I}$ may be \emph{incomplete}, \ie certain facts from the domain of interest may
not be represented in it.  The GCIs which are valid in $\mathcal{I}$ may not be
necessarily valid in the domain of interest.  This problem is very similar to the problem
solved by attribute exploration, and it can indeed be shown that attribute exploration
applied to the context $\con K_{\mathcal{I}}$ can be transferred into an algorithm for
\emph{model exploration} of $\mathcal{I}$.  This algorithm then allows to interactively
compute bases of $\mathcal{I}$, allowing an expert to provide missing facts when required.
In this way, learning GCIs which are invalid in the domain of interest can be avoided.

\section{Other Related Work}
\label{sec:related-work}

The work of Baader and Distel is not the first attempt to bring together the worlds of
description logics and formal concept analysis.  Indeed, there have been several previous
attempts to utilize formal concept analysis for description logic applications, and to add
ideas from description logics to notions of formal concepts analysis.

One of the first results in description logics that utilizes formal concept analysis is
the work of Baader~\cite{Baader-KRUSE-95}.  In this work, Baader uses the attribute
exploration algorithm on a special formal context to compute a minimal representation of
the subsumption hierarchy between all conjunctions of the defined concept names of a given
acyclic TBox $\mathcal{T}$ formulated in the logic $\ALC$.  To this end, Baader extends
the classical tableau algorithm for \ALC to decide subsumption between \emph{single}
defined concept names~\cite{journals/ai/Schmidt-SchaussS91}, and extends it in such a way
that it provides counterexamples to instances of the subsumption problem.  These
counterexamples are then collected into a suitable formal context, and from this context
the attribute exploration algorithm eventually computes the canonical base.  These
implications give rise to a set of GCIs, which can then be used to decide subsumption
between conjunctions of defined concept names of $\mathcal{T}$.

The results obtained by Baader have been further generalized by
Stumme~\cite{stumme96concept} to include also disjunction.  For this, a generalization of
attribute exploration called \emph{distributive concept
  exploration}~\cite{conf/ki/Stumme98} has been used.

Another use from formal concept analysis for description logic applications is in
\emph{knowledge base completion}~\cite{Sert07,conf/ijcai/BaaderGSS07}, for which again
attribute exploration was used.  For this, GCIs of the form
\begin{equation*}
  \bigsqcap U \sqsubseteq \bigsqcap V
\end{equation*}
are asked to the expert, where $U, V \subseteq M$ for some previously chosen set $M$ of
\emph{interesting concepts}.  The goal is then to ensure the given knowledge base is
complete with respect to all these GCIs, \ie the knowledge base should entail all such
GCIs which are confirmed by the expert, and should contain counterexamples for all other
GCIs of this type.  The most significant challenge for transferring attribute exploration
to this setting is to deal with the \emph{open world semantics} of description logic
knowledge bases: if a fact is not entailed by the knowledge base, then this does not mean
that the negated fact holds.  For this, attribute exploration is generalized to work on
\emph{partial contexts}, \ie formal context in which certain crosses are unknown.  The
resulting algorithm has been implemented as a plugin named \emph{OntoComp} for the
ontology editor \emph{Protégé}~\cite{conf/esws/Sertkaya09}.

A third prominent application of ideas of formal concept analysis in description logics is
the work of Rudolph on \emph{relational
  exploration}~\cite{phd/de/Rudolph2006,conf/iccs/Rudolph04}.  In this approach the target
description logic is \FLE, the extension of \EL by value restriction ($\forall$).  The
domain of interest is not represented as an interpretation, but by means of \emph{binary
  power context families}~\cite{DBLP:conf/iccs/PredigerW99}, which however can easily be
considered as an interpretation.  Then the exploration process is conducted in several
phases: in phase $k$, concept descriptions with \emph{role depth} at most $k$ are
considered as attributes of the current formal context, and on this formal context
attribute exploration is performed.  Rudolph then shows that this process has only to be
considered up to a certain maximal role depth, and that the resulting set of implications
can be used to decide whether an arbitrary GCI $C \sqsubseteq D$ is valid or not in the
domain represented by the expert.  However, it is not shown whether and how this set of
implications can be transferred into a base of the domain.  Indeed, the decision procedure
for checking whether $C \sqsubseteq D$ holds in the domain or not is rather complicated.
Thus, no GCIs are learned from this approach, and thus it cannot be used to obtain
terminological knowledge from relational data.

The aforementioned approach of \emph{power context families} is an attempt to add
description logic expressibility to the world of formal concept analysis.  In its easiest
form a formal context is equipped with a family of relations $\mathcal{R}$ on the object
set to obtain a \emph{relational context}.  Based on this notion, \emph{terminological
  attribute logic}~\cite{books/math/Prediger00} has been introduced that allows to define
new attributes in terms of old ones, using the relational context to extend the incidence
relation to the newly defined attributes.  With this semantics, terminological attribute
logic can be seen as a syntactic variant of the of \ALC extended by inverse roles, negated
roles and the identity role.  Terminological attribute logic can also be defined for
\emph{many-valued contexts} to provide a method for \emph{logical
  scaling}~\cite{conf/krdb/PredigerS99}, which transforms many-valued contexts into the
usual (two-valued) formal contexts in another way as the usual scaling approach of formal
concept analysis.

Another approach to bring a flavor of description logics to formal concept analysis is
\emph{relational concept analysis}~\cite{conf/icfca/RouaneHNV07,
  journals/amai/HaceneHNV13}.  The basic structure in this approach is a \emph{relational
  context family}, which consists of a family of formal context and a set of relations
between objects of possibly different contexts of this family.  Using a method called
\emph{relational scaling} new attributes $r : C$ are added to the formal contexts, which
roughly correspond to concept descriptions of the form $\forall r. C$ or $\exists r. C$,
where however $C$ is now a formal concept of a formal context of the family.  In an
iterative process, relational scaling is used to construct lattices from all formal
contexts of the relational context family.  These lattices can then be used to derive
assertional and terminological knowledge formulated in the description logic \FLE.

Other research that is related to this work are approaches in formal concept analysis and
description logics to tackle the problem of \emph{uncertainty} and \emph{vagueness}.  In
the area of formal concept analysis, the most notable and relevant work is the one by
Luxenburger~\cite{diss:Luxenburger,Luxenburger91}, who considers implications in formal
context together with an \emph{accuracy} (confidence).  Luxenburger then studies the
problem of \emph{realizations} of partial implications, which in terms of logic is just
the question whether a set of partial implications is satisfiable.  The results obtained
here give a characterization in terms of \emph{linear programs}.  Furthermore, he studies
the problem of finding \emph{bases} of partial implications, and we shall use the main
ideas in our later considerations.  Luxenburger's ideas have been used in the area of data
mining, for instance to obtain smaller representations of \emph{association
  rules}~\cite{DBLP:conf/ki/StummeTBPL01}.

Another prominent approach to handle knowledge that may not be completely correct is to
consider fuzzy extensions of the respective formalisms.  Those exist for both description
logics~\cite{journals/fss/BobilloS09,journals/ws/LukasiewiczS08} and formal concept
analysis~\cite{Pollandt97b,conf/cla/BelohlavekV05}, and are either based on Zadeh's
original approach to fuzzy logics~\cite{journals/iandc/Zadeh65}, or on the approach by
Hájek~\cite{hajek1998metamathematics}, in which the semantics is defined using
\emph{t-norms} on lattices.  In both cases, logical facts (implications, assertional
knowledge, terminological knowledge) are annotated with \emph{truth values} from an
underlying lattice, and the semantics then allows to infer truth values for previously
unknown facts, or at least bounds thereof.

Finally, a completely different approach to learning terminological knowledge has been
developed recently~\cite{conf/dlog/KonevLW13}, based on a general framework of \emph{query
  learning} proposed by~\cite{journals/ml/Angluin87}.  In contrast to the work by Baader
and Distel, this approach tries to learn TBoxes $\mathcal{T}$ by posing queries to an
\emph{oracle}.  These queries are either \emph{entailment queries}, in which the oracle
has to decide whether a proposed GCI is entailed by the TBox $\mathcal{T}$ to be learned,
or \emph{equivalence queries}, where the oracle has to decide whether a given TBox is
equivalent to $\mathcal{T}$.  The work~\cite{conf/dlog/KonevLW13} then considers
the question for which description logic the TBox $\mathcal{T}$ can be learned in
polynomial time.  In particular, it is shown that if $\mathcal{T}$ is an \emph{acyclic
  \EL-TBox}, then it cannot be learned in polynomial time.

Note that entailment queries are similar to the questions proposed to an expert during
attribute exploration.  In fact, it is possible to show that a certain special case of
query learning~\cite{journals/ml/AngluinFP92} can be used to obtain an alternative
computation of the canonical base~\cite{journals/ml/AriasB11}.

\section{Contributions}
\label{sec:contributions}

The goal of this work is to extend the work by Baader and Distel to include the
possibility that the initially given interpretation $\mathcal{I}$ does not correctly
represent the domain of interest, and instead contains \emph{errors}.  The motivation for
this extension stems from the observation that for practical applications it is almost
always impossible to obtain data sets which are free of errors.  To still be able to apply
the results of Baader and Distel thus requires a methodology to handle these errors.

The main contributions of this thesis are the following.

\subsection{Experiments with Extracting Valid GCIs}
\label{sec:exper-with-extr}

All results obtained by Baader and Distel are \emph{effective}, meaning that the resulting
algorithms can be implemented and applied to arbitrary data.  As a first contribution of
this work, we shall present an implementation of these algorithms in
\Cref{sec:computing-bases-from}.  We then apply this implementation to relational data
from the \emph{DBpedia project}~\cite{DBpedia}, which obtains its data by crawling
\emph{infoboxes} of Wikipedia articles.  We shall see that the approach by Baader and
Distel is indeed able to extract terminological knowledge from this data, and we shall
discuss the corresponding outcome in detail.

The main observation of these experiments, however, is that the errors in the DBpedia data
set inhibit GCIs from being found which would otherwise be relevant for the domain of the
chosen data.  The main example is that the GCI
\begin{equation*}
  \exists \mathsf{child}. \top \sqsubseteq \mathsf{Person}
\end{equation*}
stating the fact that every individual which has a child is a person, was not found during
our experiments.  The reason for this is that input data contained four counterexamples
for this GCI, which however were all erroneous.  On the other hand, the input data
contained 2547 \emph{positive examples} for this GCI.  This shows that the original
approach of Baader and Distel is very sensitive to errors in the input data, even if they
are comparably rare.

\subsection{Extracting GCIs with High Confidence from Erroneous Data}
\label{sec:extracting-gcis-from}

A main results from our experiments is that errors in the input data can inhibit otherwise
valid GCIs from being extracted.  Based on the assumption that the input data must be of
sufficient \emph{quality}, \ie must not contain too many errors, we generalize the
approach by Baader and Distel from computing bases of valid GCIs to computing bases of
GCIs which are \emph{almost valid} in the input data.  To formalize the notion of being
\emph{almost valid}, we make use of the notion of \emph{confidence} as it is used in
data-mining, and transfer it to the setting of GCIs.  Instead of computing bases of valid
GCIs, we then want to compute bases of GCIs whose confidence is above a certain threshold
$c$, for some chosen value $c \in [0,1]$.  Those GCIs we shall call GCIs \emph{with high
  confidence}.  We shall see that we can generalize most of the results of Baader and
Distel accordingly, using Luxenburger's ideas on his investigation of partial implications
in formal contexts.  An example for this is the result that bases of the induced context
of a finite interpretation give rise to a base of the finite interpretation itself.  We
shall see that we can generalize this result such that bases of implications with high
confidence in the induced context give rise to bases of GCIs with high confidence in the
finite interpretation.  Finally, we shall apply our results to the data sets we used for
our experiments to show that certain errors in the input data can be handled with out
approach.

\subsection{Exploration by Confidence}
\label{sec:expl-conf-2}

The approach of considering GCIs with high confidence is a purely heuristic one: by
considering GCIs with high confidence, we can ignore rare errors in the input data.
However, it is not guaranteed that this approach also ignores \emph{rare counterexamples},
\ie counterexamples which are actually valid, but occur so infrequently that the
confidence measures ignores them.  In this case, an external source of information is
needed that can distinguish between errors and rare counterexamples in the data.  An
example for such an external source of information could be a human expert, which then
considers all such counterexamples manually, and decides whether they are valid or not.

Expert interaction can also be used to tackle another problem with data, namely its
\emph{incompleteness}: for certain GCIs relevant counterexample may exist, but may not be
present in the given data set.  In other words, we still assume that our domain is
represented by an interpretation, the so-called \emph{background interpretation}, but we
only have access to some part of it.  In this case, both the original approach by Baader
and Distel, as well as our extension to GCIs with high confidence would extract those GCIs
for which relevant counterexamples are missing.  We could use the external expert to avoid
this issue, by querying this expert for possible counterexamples from the background
interpretation for all GCIs we would extract.

This expert interaction may be expensive, however, and an algorithm that keeps this
interaction to a minimum would be highly desirable.  In the case of valid implications of
a formal context, the attribute exploration algorithm would be such an algorithm, as it
asks the expert a minimal number of different questions.  Therefore, we want to generalize
attribute exploration to the setting of GCIs with high confidence to obtain an algorithm
that allows the use of an expert to distinguish between errors and rare counterexamples.

To this end, we shall consider as a first step the easier problem where we consider
\emph{implications with high confidence} instead of GCIs.  In this step, we shall
generalize attribute exploration to \emph{exploration by confidence}, where the algorithm
not only asks implications to the expert which are valid in the current context, but also
those which only have high confidence.  For this, we first investigate generalizations of
attribute exploration which allow us to explore \emph{sets of implications}.  In these
generalizations, a set $\mathcal{L}$ of implications can be specified for which the expert
should decide which elements of $\mathcal{L}$ are valid or not.  In attribute exploration,
the set $\mathcal{L}$ is just the set of all valid implications of a given formal context.
For the case of implications with high confidence, the set $\mathcal{L}$ is then just the
set of all implications whose confidence is above a certain threshold $c$.

\subsection{Model-Exploration by Confidence}
\label{sec:model-expl-conf}

The problem of incomplete data already arises in the case of valid GCIs, and to approach
this problem Baader and Distel propose extensions of attribute exploration which also work
with valid GCIs.  On of these extensions, called \emph{model exploration}, works mostly in
the same way as attribute exploration does, with the difference that the expert now gets
asked GCIs for confirmation instead of implications.  Model exploration is essentially
attribute exploration of the induced context of the given interpretation, although several
technical problems have to be dealt with.

One of these problems it that the attribute set of the induced context depends on the
background interpretation.  Clearly, the background interpretation is not available during
the exploration process.  Model exploration solves this problem by computing the set of
attributes of the induced context incrementally during the computation.  Another problem
is the way counterexamples have to be specified: because of the \emph{closed world
  semantics} of interpretations, every counterexample provided by the expert has to be
\emph{complete}.  This means that as soon as the expert wants to provide an element as a
counterexample, all elements which can be reached via directed edges from this elements in
the background interpretation have to be provided as well.  In other words, the
counterexamples provided by the expert have to be \emph{connected subinterpretations} of
the background interpretation.

To generalize model exploration to GCIs with high confidence, we essentially follow the
argumentation of model exploration.  More precisely, we shall consider exploration by
confidence of the induced context of the given interpretation, and transform it to
\emph{model exploration by confidence}, in a very similar way as model exploration arises
from attribute exploration of the induced context.

A notable difference to the argumentation of Baader and Distel is that we first have to
generalize our results about computing bases of GCIs with high confidence to include the
possibility that certain elements of the interpretation are \emph{trusted}, in the sense
that as soon as a trusted element is a counterexample for some GCI, this GCI is not
considered any further, even if its confidence is high enough.  The motivation for this
generalization stems from the fact that we consider all counterexamples provided by the
expert to be trusted.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../main"
%%% End: 

%  LocalWords:  Protégé OntoComp
