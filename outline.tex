\documentclass[english,fleqn]{scrartcl}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{babel}

\usepackage[nobackrefs]{preamble}
\usepackage[subtle]{savetrees}

\pagestyle{empty}

\begin{document}

\medskip
\begin{center}
  \normalsize Abstract of the thesis\\
  \LARGE\textbf{Learning Terminological Knowledge\\ with High Confidence from Erroneous
    Data}\\
  \bigskip%
  \large Dipl.-Math.\ Daniel Borchmann
\end{center}
\bigskip
\bigskip

\noindent
Knowledge is a necessary requirement for intelligent behavior.  For computers, in
particular, it is therefore indispensable to first obtain relevant knowledge before they
can act intelligently in certain situations.  The problem of obtaining this knowledge,
commonly referred to as the problem of \emph{knowledge acquisition} or just
\emph{learning}, is hard to address, because computers, in contrast to human beings, are
not able to learn autonomously.  Moreover, for computers it is relevant that the knowledge
they obtain is represented in a way that is suitable for them to work with.  Thus, the
problem of \emph{knowledge representation} has also to be tackled to enable intelligent
behavior of machines.

A popular choice to represent knowledge for computers is to use logic-based formalisms,
because they yield predictable and reliable behavior.  In the area of logic-based
knowledge representation formalism, \emph{description logics}~\cite{DLhandbook} are one of
the most successful approaches.  Using \emph{description logic knowledge bases} it is
possible to represent \emph{assertional} and \emph{terminological} knowledge.  Assertional
knowledge express facts about one or two individuals the domain for which knowledge has to
be learned.  Examples for this kind of knowledge are \enquote{Abraham Lincoln was a
  president}, or \enquote{John McCarthy was a professor at Stanford University}.  In other
words, assertional knowledge expresses \emph{assertions} (\emph{facts}) about certain
individuals.  Terminological knowledge represents common knowledge about all individuals
of the domain of interest.  Examples for this kind of knowledge are \enquote{all humans
  are mortal} or \enquote{every human has a head}.  Thus, terminological knowledge
represents dependencies between different \emph{terms}, called \emph{concept
  descriptions}.

If one chooses to represent knowledge using description logics, one is left with the
problem to obtain all relevant assertional and terminological knowledge about the domain
one is interested in.  Obtaining assertional knowledge is relatively easy: assuming that
one knows all individuals of the domain, one can gather all facts that are known about
them.  The difficulty here lies mostly in the problem of automating this process, in
particular if one tries to gather facts from unstructured data, like text, that is hard to
process for computers.  On the other hand, obtaining terminological knowledge cannot be
achieved this way, since one is looking for general knowledge that affects \emph{all}
individuals of the domain.  Moreover, it is not at all clear how to find the concept
descriptions that appear in this kind of knowledge.

Recent work by Baader and Distel~\cite{Diss-Felix} proposes an approach to learning
terminological knowledge, using ideas from the area of \emph{formal concept
  analysis}~\cite{fca-book}.  In this approach it is assumed that the domain of interest
is representable as a \emph{finite interpretation}.  Intuitively, finite interpretations
can be thought of as directed edge- and vertex-labeled graphs.  Baader and Distel then
propose to learn terminological knowledge by computing \emph{finite base} of all
\emph{general concept inclusions} (GCIs) that are valid in a given finite interpretation
and are expressible using the description logic \ELbot.  GCIs are the most general means
in description logics to express terminological knowledge.  Using GCIs, the examples given
above could be reformulated as
\begin{equation*}
  \mathsf{Human} \sqsubseteq \mathsf{Mortal}, \; \mathsf{Human} \sqsubseteq \exists
  \mathsf{has}. \mathsf{Head}.
\end{equation*}
Then these two GCIs are valid in an interpretation if and only if every \emph{individual}
(node) that is labeled with \textsf{Human} is also labeled with \textsf{Mortal}, and has
an outgoing edge labeled with \textsf{has} that points to a node labeled with
\textsf{Head}.  Finite bases $\mathcal{B}$ are finite sets of valid GCIs that are
\emph{complete}, in the sense that all GCIs that are valid in the given interpretation are
entailed by $\mathcal{B}$.

The approach of Baader and Distel is interesting for practical applications.  This is
because finite interpretations can be seen as a different form of \emph{linked data}, the
data-format used by the \emph{Semantic Web}.  The first contribution of this work is to
apply the results by Baader and Distel to linked data obtained by the DBpedia
project~\cite{DBpedia}.  These experiments show that this approach indeed allows us to
learn terminological knowledge from data.

These experiments also reveal a disadvantage of the algorithm: considering only valid GCIs
leads to a high sensitivity of the extracted knowledge to \emph{errors} in the data.  In
other words, as soon as a single error is contained in the data, all valid GCIs affected
by this error are not extracted anymore.  Since one cannot assume that data, and linked
data in particular, is free of errors, this sensitivity severely impairs the usefulness of
Baader and Distel's approach.

One can assume, however, that the given data represents the domain of interest
\enquote{sufficiently well}, in the sense that it does not contain too many errors.  Based
on this assumption, one can think of alleviating the sensitivity of Baader and Distel's
approach to errors in the data by considering GCIs that are \enquote{almost valid}
instead.  This way, GCIs that are erroneously invalidated by sporadic errors are still
retrieved from the data.

It is the goal of this thesis to generalize the results by Baader and Distel accordingly.
For this, the notion of \emph{confidence} as used in
data-mining~\cite{arules:agrawal:association-rules} is transferred to GCIs.  Intuitively,
the confidence of a GCI $C \sqsubseteq D$ in a finite interpretation $\mathcal{I}$
quantifies how often this GCI is correct, in the sense that if an individual in
$\mathcal{I}$ satisfies the concept description $C$, then it also satisfies the concept
description $D$.  For example, the confidence of $\mathsf{Human} \sqsubseteq
\mathsf{Mortal}$ in a finite interpretation would be the number of individuals labeled
with both $\mathsf{Human}$ and $\mathsf{Mortal}$, divided by the number of individuals
just labeled with $\mathsf{Human}$.

The notion of confidence of GCIs gives a measure of \enquote{how valid} a GCI is in a
finite interpretation $\mathcal{I}$: to say that a GCI is \emph{almost valid} in
$\mathcal{I}$ then means the confidence of this GCI in $\mathcal{I}$ is above a chosen
\emph{confidence threshold} $c \in [0,1]$.  Such an almost valid GCI is then also called a
GCI \emph{with high confidence}.  The task is then interested in finding finite bases for
such GCIs with high confidence, \ie to find finite sets $\mathcal{B}$ of GCIs with high
confidence that are \emph{complete}, in the sense that all GCIs with high confidence are
entailed by $\mathcal{B}$.

First results on computing such bases are achieved by exploiting the close connection
between description logics and formal concept analysis that has already been used in the
approach by Baader and Distel.  Based on this connection as well as on results by
Luxenburger on \emph{partial implications} in formal contexts~\cite{diss:Luxenburger},
methods are discussed that explicitly describe bases of GCIs with high confidence.
Furthermore, results are obtained that allow to compute such bases from bases of
implications with \emph{high confidence} in formal contexts.  All these findings are
applied to the data set used for the initial experiments, and evaluated for their
practicability with respect to handling sporadic errors.

A drawback of this approach is that that considering GCIs with high confidence is purely
heuristic, in the sense that counterexamples to GCIs are ignored if they are just not
frequent enough.  In particular, if the initial interpretation contains rare but valid
counterexamples, then these are ignored as well.  To remedy this, an external source of
information is necessary that is able to distinguish between these rare counterexamples
and errors.  An example for such a source would be a human expert for the domain of
interest.

Given a finite base of GCIs with high confidence, one could address this problem by
letting an expert verify every GCI contained in this base.  All GCIs rejected by the
expert are then removed from the base.  This naive approach has the disadvantage that as
soon as a GCI is removed, other GCIs may have to be added to ensure completeness of the
base, and it is by far clear how this can be done effectively.  In the worst case, the
base has to be recomputed completely.

A more systematic approach is based on \emph{model exploration}, an algorithm devised by
Baader and Distel based on \emph{attribute exploration}, a knowledge acquisition algorithm
from formal concept analysis.  Model exploration is concerned with the issue of
\emph{incomplete data}: a finite interpretation may only incompletely represent a domain
of interest by missing certain individuals.  In this case, it may happen that GCIs that
are valid in the interpretation do actually not hold in the domain.  Model exploration
solves this issue by using the expert to interactively verify every GCI that is computed,
providing missing individuals if necessary.  The algorithm ensures that the resulting set
of GCIs is a finite base of the domain, and not only of the interpretation.

In this thesis, model exploration is generalized to \emph{model exploration by
  confidence}.  During the run of this algorithm, the expert has to verify GCIs with high
confidence in the original data, and may provide valid counterexamples if necessary.  GCIs
that are invalidated by such counterexamples are not considered any further, even if their
confidence would be high enough.  In this way, the expert can distinguish between errors
and rare counterexamples in the data.

\printbibliography{}

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
